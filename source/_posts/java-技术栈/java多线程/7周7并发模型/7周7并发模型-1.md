---
title: 7周7并发模型-第一周
date: 2020-04-24 19:31:59
tags:
- java
- company
- concurrent

categories:
- java
- book_notes



---

起初还在想这么薄的书怎么能学七周呢，原来大部分内容都隐藏在作业里自学了。
第一周参上
<!--more-->

<!-- TOC -->

- [线程与锁](#%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%94%81)
    - [互斥与内存模型](#%E4%BA%92%E6%96%A5%E4%B8%8E%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B)
        - [作业](#%E4%BD%9C%E4%B8%9A)
            - [内存模型](#%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B)
                - [jsr 133](#jsr-133)
                - [重排序](#%E9%87%8D%E6%8E%92%E5%BA%8F)
                - [final](#final)
                - [volatile](#volatile)
            - [双重检查锁](#%E5%8F%8C%E9%87%8D%E6%A3%80%E6%9F%A5%E9%94%81)
                - [反模式](#%E5%8F%8D%E6%A8%A1%E5%BC%8F)
            - [对象初始化的线程安全](#%E5%AF%B9%E8%B1%A1%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8)
    - [超越内置锁](#%E8%B6%85%E8%B6%8A%E5%86%85%E7%BD%AE%E9%94%81)
        - [ReentrantLock](#reentrantlock)
        - [条件变量](#%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F)
        - [原子变量](#%E5%8E%9F%E5%AD%90%E5%8F%98%E9%87%8F)
        - [自习](#%E8%87%AA%E4%B9%A0)
            - [ReentrantLock](#reentrantlock)
            - [ReentrantLock](#reentrantlock)
            - [虚假唤醒](#%E8%99%9A%E5%81%87%E5%94%A4%E9%86%92)
            - [AtomicIntegerFieldUpdater](#atomicintegerfieldupdater)
    - [站在巨人的肩膀上](#%E7%AB%99%E5%9C%A8%E5%B7%A8%E4%BA%BA%E7%9A%84%E8%82%A9%E8%86%80%E4%B8%8A)
        - [线程池](#%E7%BA%BF%E7%A8%8B%E6%B1%A0)
        - [写入时复制](#%E5%86%99%E5%85%A5%E6%97%B6%E5%A4%8D%E5%88%B6)
        - [一个绝好的例子](#%E4%B8%80%E4%B8%AA%E7%BB%9D%E5%A5%BD%E7%9A%84%E4%BE%8B%E5%AD%90)
        - [自习](#%E8%87%AA%E4%B9%A0)
            - [forkjoinpool](#forkjoinpool)
            - [work-stealing](#work-stealing)
            - [CountDownLatch与CyclicBarrier](#countdownlatch%E4%B8%8Ecyclicbarrier)
            - [阿姆达尔定律](#%E9%98%BF%E5%A7%86%E8%BE%BE%E5%B0%94%E5%AE%9A%E5%BE%8B)
            - [古斯塔夫森定律](#%E5%8F%A4%E6%96%AF%E5%A1%94%E5%A4%AB%E6%A3%AE%E5%AE%9A%E5%BE%8B)
            - [毒丸](#%E6%AF%92%E4%B8%B8)

<!-- /TOC -->


# 线程与锁

## 互斥与内存模型
多线程的主要问题的就是竞态，即代码行为取决于各操作的时序。
解决方案是对count进行同步(synchronize)访问。一种是使用java原生的内置锁(互斥锁mutex、管程(monitor)或临界区(critical section))来同步调用。
**乱序执行是完全有可能发生的**
不论是c还是java，编译器都有静态优化，硬件上也会有乱序执行，jvm还有动态优化。
原则上，如果读线程和写线程不进行同步就不保证可见性（可见性就是..某个变量在这里赋值在另一边能不能取到）
死锁。哲学家吃饭先左后右直到所有人都把左手筷子拿起。
简单的避免是给锁添加一个全局顺序，比如每个人按筷子序号拿而非先左后右的顺序，则不会出现死锁。
不要调用外星方法：你无从知道外星方法会不会也持有一把锁。它可能会做任何事情。
避免的一种方法是在遍历之前对listeners进行保护性复制，再针对副本进行遍历
```java
private void updateProgress(int n)
{
    ArrayList<ProgressListener> listenersCopy;
    synchronized(this){
        listenersCopy = (ArrayList<ProgressListener>) listeners.clone();
    }
    for(ProgressListener listener: listenersCopy)
        listener.onProgress(n);
}
```
如此一来就不会把整个方法编程synchronized，不仅在外星方法时无锁，还大大减少了代码持有锁的时间，甚至如果修复了在遍历时remove的错误。

### 作业
+ ~~todo~~ 自学JSR 133的FAQ
+ ~~todo~~ java内存模型如何保证对象初始化线程安全？是否必须加锁才能在线程之间安全地公开对象？
+ ~~todo~~ 双重检查锁，反模式
+ ~~todo~~ william pugh 的网站：java内存模型

#### 内存模型
在处理器级别，一个内存模型定义应该实现的充分必要条件（necessary and sufficient conditions）是其它处理器写入内存的数据对于当前处理器是可见的，当前处理器写入内存的数据对其它处理器也是可见的。如果是一个强大的内存模型（a strong memory model），那么所有处理器在任何时候读取内存中任何位置，都能得到一样的值；而对于较弱的内存模型（a weaker memory model），只有在特殊情况下，通过调用内存栅栏（where special instructions, called memory barriers）将缓存数据刷新或者失效（flush or invalidate the local processor cache），这样才能获取其它处理器处理后的数据或者让其它处理器知道当前处理器处理的数据。这些内存栅栏（memory barriers）通常在加锁和解锁操作的时候执行；它们对于高级语言（a high level language）而言是不可见的。
当前处理器设计的趋势是鼓励弱内存模型，因为弱内存模型对于缓存一致性（多处理器同时涉及同一主内存）的放宽使得多处理器和大内存有更大的可扩展性
当前线程的写操作何时对其它线程可见，这个问题因为编译器的重排序而变得复杂。比如，编译器可能会觉得往后移动一个写操作会更加有效率；只要这个代码移动不会改变程序语义，这样做没有任何问题。如果编译器推迟了一个操作，只有到程序运行完成，其它线程才能看见数据的变化，这就是缓存的作用。(由于缓存的存在，指令重排序不会马上影响到内存中数据的变化，因为操作缓存数据即可)
Java 内存模型描述了在多线程代码中，哪种行为是合法的，以及线程之间如何通过内存交互。它描述了程序中变量之间的关系，以及在实际计算机的内存或者寄存器中存储和检索它们的低级细节。它可以通过各种各样的硬件和各种各样的编译器优化来实现

Java 内存模型是为了屏蔽不同硬件处理器架构以及指令重排序对程序的并发影响而提出的一套规范，保证正确应用这套规范的程序可以在任何硬件处理器上都能够执行正确的并发操作。

资料指出，包括了缓存导致的内存可见性（线程更新对象对其他线程不可见）和重排序的可见性；指令序列的重排序；数据依赖；

---
pc寄存器 java虚拟机栈 本地方法栈
   java堆          方法区(Runtime Constant Pool)
---上面是java虚拟机内的内存
所有线程共享的数据 各个线程共享的数据 运行时常量

---
可能有点小错误，不过概念部分问题不大[https://www.jianshu.com/p/76959115d486]
1. pc寄存器(程序计数器)
(线程私有)的存在是为了线程切换可以恢复到正确执行位置
2. java栈(虚拟机栈)
(线程私有)，描述的是java方法执行的内存模型。**每个方法被执行的时候都会创建一个栈帧用于存储局部变量表，操作栈，动态链接，方法出口等信息。每一个方法被调用的过程就对应一个栈帧在虚拟机栈中从入栈到出栈的过程。**
>栈帧: 是用来存储数据和部分过程结果的数据结构。
>栈帧的位置:  内存 -> 运行时数据区 -> 某个线程对应的虚拟机栈 -> ?
>栈帧大小确定时间: 编译期确定，不受运行期数据影响。

平时说的栈一般指局部变量表部分
  是一片连续的内存空间，用来存放方法参数，以及方法内定义的局部变量，存放着编译期间已知的数据类型(八大基本类型和对象引用(reference类型),returnAddress类型(指向一条字节码指令的地址)。
需要注意的是，局部变量表所需要的内存空间在编译期完成分配，当进入一个方法时，这个方法在栈中需要分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表大小。
3. 本地方法栈
是与虚拟机栈发挥的作用十分相似,区别是虚拟机栈执行的是Java方法(也就是字节码)服务，而本地方法栈则为虚拟机使用到的native方法服务，可能底层调用的c或者c++,我们打开jdk安装目录可以看到也有很多用c编写的文件，可能就是native方法所调用的c代码。
4. 堆
堆是java虚拟机管理内存最大的一块内存区域，因为堆存放的对象是线程共享的，所以多线程的时候也需要同步机制
所有对象实例及数组都要在堆上分配内存，但随着JIT编译器的发展和逃逸分析技术的成熟，这个说法也不是那么绝对，但是大多数情况都是这样的。
  逃逸分析:通过逃逸分析来决定某些实例或者变量是否要在堆中进行分配，如果开启了逃逸分析，即可将这些变量直接在栈上进行分配，而非堆上进行分配。这些变量的指针可以被全局所引用，或者其其它线程所引用。
  它是所有线程共享的，它的目的是存放对象实例。同时它也是GC所管理的主要区域，因此常被称为GC堆，又由于现在收集器常使用分代算法，Java堆中还可以细分为新生代和老年代，再细致点还有Eden(伊甸园)空间之类的不做深究。
5. 方法区
方法区同堆一样，是所有线程共享的内存区域，为了区分堆，又被称为非堆。
用于存储已被虚拟机加载的类信息、常量、静态变量，如static修饰的变量加载类的时候就被加载到方法区中。
方法区有很多实现，java8中废弃了永久代，使用了元空间。

---
java线程-工作内存-（save和load）|是一体->(主)
java线程-工作内存-（save和load）|是一体->(内)
java线程-工作内存-（save和load）|是一体->(存)

Java内存模型与硬件内存架构之间存在差异。硬件内存架构没有区分线程栈和堆。对于硬件，所有的线程栈和堆都分布在主内存中。部分线程栈和堆可能有时候会出现在CPU缓存中和CPU内部的寄存器中。
Java内存模型中的线程的工作内存（working memory）是cpu的寄存器和高速缓存的抽象描述。




##### jsr 133
JSR，Java Sepcification Requests，Java 规范提案
JSR 133： Java Memory Model and Thread Specification，Java 内存模型与线程规范
JSR 133 定义了一个新的内存模型，修复了之前内存模型的缺陷。为实现这一目的，final 和 volatile 的语义会有所变化。

##### 重排序
重排序指的是程序在编译，加载，链接，运行的过程中，随时都有可能程序指令被重新排列，同时，这一过程也会给上层显示有一种按序执行的假象。对于单线程程序，不需要关心重排序带来的影响；对于多线程程序，如果访问同一个变量，重排序可能会影响结果的正确性，所以需要同步。

新的内存模型在内存操作（写操作，读操作，加锁，解锁）和其它线程操作（start 和 join）中执行部分排序，就是说一些操作一定会在另一些操作之前，称之为 happens-before

这种排序规则如下：

当前线程的每一个动作都 happens-before 程序中后来的线程
对同一个监视器的解锁操作 happens-before 后续的加锁操作
对一个 volatile 变量的读操作 happens-before 后续对同一个变量的读操作
对一个线程的 start() 调用 happens-before 这个线程启动后的任何动作
当前线程的所有动作都 happens-before 其它线程（对当前线程执行 join() 操作）

保证进入同步块的线程操作对于其它阻塞在同一个监视器的线程可见。

##### final
final 字段的值可以在对象构造器中设置。假设对象被“正确”的构造，那么一旦对象构造完成，这个 final 字段的值将被所有线程可见，不需要同步操作。另外，final 字段引用的其它对象或数组改变后，final 字段的值也一定会改变

怎么样才是对象被正确的构造？简单的说，对象引用不应该在构造期间”泄露”。（举例：Safe construction techniques）换句话说，不应该放置构造期间的对象引用在另一个线程可能会看到它的地方；不要赋值给静态字段；不要将其注册为其它对象的监听器，等等。这些事情应该在构造完成后操作，而不是在构造期间。

>不要在构造器中使用 "this" 引用。如果无法避免，确保它不会对其它线程可见；
不要在构造器中创建非静态内部类；
不要再构造器中启动线程。

```java
public FinalFieldExample() { // bad!
  x = 3;
  y = 4;
  // bad construction - allowing this to escape
  global.obj = this;
}
```
这样无法保证能够看到正确的final变量值，因为线程读取了this引用，通过指令重排序final变量就泄露了当前对象的引用。

如果字段是 final 修饰的，那么能够保证构造器结束后，代码能够看到该字段所指向的对象或者数组最新的值。所以，这种情况下，不需要担心其它线程看见了这个字段引用指向的数组，但是看不到数组最新的值。再次声明，这个 “正确” 指的是 “对象构造器结束时最新的值” 而不是 “最新有效的值”

正确构造后的 final 字段能够被所有线程可见，但是无法确定 final 字段引用的数组或者对象是最新的值，所以需要结合实际程序，在多线程情况下最好是执行同步操作。

##### volatile
在新内存模型中， volatile 变量仍旧无法被重排序，差异是 volatile 变量周围的正常变量也不会很容易被重排序
实际上，因为新的内存模型对 volatile 字段对其周围字段访问设置了更严格的约束条件，当线程 A 写入 volatile 字段 f 时，任何对线程 A 可见的变量也对写入字段 f 的线程 B 可见。
```java
class VolatileExample {
  int x = 0;
  volatile boolean v = false;
  public void writer() {
    x = 42;
    v = true;
  }

  public void reader() {
    if (v == true) {
      //uses x - guaranteed to see 42.
    }
  }
}
```
事实上，volatile 的语义基本上加强到同步的水平。对 volatile 字段的每一次读和写就像半个同步操作，即保证了可见性。

**final 和 volatile 不能同时使用，会产生编译错误**

#### 双重检查锁
简单的说，单例模式下多线程同时可能造成多实例。所以要加锁，双重检查锁就是对单锁的优化（单锁性能开销过大了因为每次都要进synchronize方法判断）
```java
public class Singleton {
    private static Singleton uniqueSingleton;//!!!! must have volatile

    private Singleton() {
    }

    public Singleton getInstance() {
        if (null == uniqueSingleton) {
            synchronized (Singleton.class) {
                if (null == uniqueSingleton) {
                    uniqueSingleton = new Singleton();   // error
                }
            }
        }
        return uniqueSingleton;
    }
}
```
检查是否初始化，获取锁，再次检查是否初始化，这样只有在初始化的时候才会出现加锁的情况，而且避免了问题。
问题在于这里error的那行代码，也会有三步：分配内存空间、初始化对象、将对象指向刚分配的内存空间。这里的二三步是可能重排序的。
133的volatile解决了这个问题。

##### 反模式
该模式在某些语言在某些硬件平台的实现可能是不安全的。有的时候，这一模式被看做是反模式。
............我tm觉得这个百度百科给出来的就很搞笑。

#### 对象初始化的线程安全
初始化顺序：初始化类变量(并未赋值)，执行静态代码块和类变量定义式，初始化实例变量，执行构造代码块和实例变量定义赋值式，执行构造函数

在执行类的初始化期间，JVM会去获取一个锁，会造成隐蔽的线程阻塞

final可以公开对象，但正如上面所说，难以保证是最新的正确的值。


## 超越内置锁
J.U.C

### ReentrantLock
ReentrantLock可以中断，可以设置超时
交替锁。比如我们想要在链表中插入一个节点。我们只需要锁住链表的一部分即可
```java
class ConcurrentSortedList {
  private class Node {
    int value;
    Node prev;
    Node next;
    ReentrantLock lock = new ReentrantLock();

    Node() {}

    Node(int value, Node prev, Node next) {
      this.value = value; this.prev = prev; this.next = next;
    }
  }

  private final Node head;
  private final Node tail;

  public ConcurrentSortedList() {
    head = new Node(); tail = new Node();
    head.next = tail; tail.prev = head;
  }

  //insert方法是有序的 遍历列表直到找到第一个值小于等于新插入的值得节点,在这个位置插入
  public void insert(int value) {
    Node current = head;
    current.lock.lock();
    Node next = current.next;
    try {
      while (true) {
        next.lock.lock();
        try {
          if (next == tail || next.value < value) {
            Node node = new Node(value, current, next);
            next.prev = node;
            current.next = node;
              //!!!这里return要在两个finally都执行完后才会执行啊!!!但只是finally里的.不过要是return换成exit(0)就直接退出了

            return; 
          }
        } finally { current.lock.unlock(); }
        current = next;
        next = current.next;
      }
    } finally { next.lock.unlock(); }
  }

  public int size() {
    Node current = tail;
    int count = 0;

    while (current.prev != head) {
      ReentrantLock lock = current.lock;
      lock.lock();
      try {
        ++count;
        current = current.prev;
      } finally { lock.unlock(); }
    }

    return count;
  }

  public boolean isSorted() {
    Node current = head;
    while (current.next.next != tail) {
      current = current.next;
      if (current.value < current.next.value)
        return false;
    }
    return true;
  }
}

class LinkedList {
  public static void main(String[] args) throws InterruptedException {
    final ConcurrentSortedList list = new ConcurrentSortedList();
    final Random random = new Random();

    class TestThread extends Thread {
      public void run() {
        for (int i = 0; i < 10000; ++i)
          list.insert(random.nextInt());
      }
    }

    class CountingThread extends Thread {
      public void run() {
        while (!interrupted()) {
          System.out.print("\r" + list.size());
          System.out.flush();
        }
      }
    }

    Thread t1 = new TestThread();
    Thread t2 = new TestThread();
    Thread t3 = new CountingThread();
    //注意一下这里的用法 这里先join再interrupted的用法
    t1.start(); t2.start(); t3.start();
    t1.join(); t2.join();
    t3.interrupt();
 
    System.out.println("\r" + list.size());
 
    if (list.size() != 20000)
      System.out.println("*** Wrong size!");
 
    if (!list.isSorted())
      System.out.println("*** Not sorted!");
  }
}
```
很有参考价值的代码。

### 条件变量
用一把锁，将竞争才能够对筷子的争夺换成对状态的判断：仅当哲学家左右邻座没有进餐时，才可以进餐。换句话说，一个哲学家饥饿时，他首先锁住餐桌。这样其他哲学家无法改变状态，然后查一下左右是否进餐，没有则自己进餐并解锁餐桌，否则调用await()以解锁餐桌。吃完了开始思考就先锁住餐桌然后通知左右餐桌可以吃了。如果左右正在等待，他们将被唤醒重新锁住餐桌判断进餐。
看上去复杂得多，但是并发度显著提升。几乎可以确定可以有多个哲学家在一起吃饭，而不是拿着一根筷子干等。

```java
class Philosopher extends Thread {

    private boolean eating;
    private Philosopher left;
    private Philosopher right;
    private ReentrantLock table;
    private Condition condition;
    private Random random;
    private int thinkCount;

    public Philosopher ( ReentrantLock table ) {
        eating = false;
        this.table = table;
        condition = table.newCondition();
        random = new Random();
    }

    public void setLeft ( Philosopher left ) {
        this.left = left;
    }

    public void setRight ( Philosopher right ) {
        this.right = right;
    }

    public void run () {
        try {
            while ( true ) {
                think();
                eat();
            }
        }
        catch ( InterruptedException e ) {
        }
    }

    private void think () throws InterruptedException {
        table.lock();
        try {
            eating = false;
            left.condition.signal();
            right.condition.signal();
        } finally {
            table.unlock();
        }
        ++thinkCount;
        if ( thinkCount % 10 == 0 ) {
            System.out.println( "Philosopher " + this + " has thought " + thinkCount + " times" );
        }
        Thread.sleep( 1000 );
    }

    private void eat () throws InterruptedException {
        table.lock();
        try {
            while ( left.eating || right.eating ) {
                condition.await();
            }
            eating = true;
        } finally {
            table.unlock();
        }
        Thread.sleep( 1000 );
    }
}
```

### 原子变量
原子变量时*无锁非阻塞算法*的基础。可以不用锁和阻塞来达到同步的目的。无锁比有锁的代码更复杂。
volatile是一种低级形式的同步，它并不能解决Counter的问题(指不能保证count++的操作似乎原子的)。他保证的是变量无法被重排序，但是竞态是无法避免的，两个线程还是可能同时访问这个变量然后出现问题。现在已经有了很多低开销锁，尽量不要用volatile。

### 自习
他又来了！

+ ReentrantLock创建时可以设置一个描述公平性的变量。什么是公平的锁？
+ 什么是ReentrantReadWriteLock？和我们提到的那个有什么区别？
+ 什么是「虚假唤醒」？
+ 什么是AtomicIntegerFiledUpdater?


#### ReentrantLock
fair - true if this lock should use a fair ordering policy
哈哈，忘了吧（。
公平表示所有线程会不会以fifo的顺序来获取锁。公平锁一般用来防止「饥饿」的产生。

#### ReentrantLock
>ReentrantReadWriteLock按照字面意思是读写锁，如果你把它理解为对IO的控制，那就大错特错了（其实大多数人的直觉是这样）。其实你只要把它理解成一个数据库的事务锁就对了。众所周知数据库事务锁的特点就是，读写分离。而ReentrantReadWriteLock是类似最高级的事务级别Serializable可串行化（严格讲比这个还更严谨）。什么意思呢，意思就是，对一条数据的更新操作只影响其它对该条数据的更新操作，而读操作是不影响的。   而并发锁Lock也好，synchronizy也好，是直接把读写都锁住的。就是说，该代码块一但锁住之后，既不能读也不能写。 但这样是有问题的，有些线程只是想读取一下数据，我又不改数据，你锁它干嘛呢？（类似事物吧） 所以ReentrantReadWriteLock把锁拆分成了读锁和写锁。  写锁之间的互斥的，但读锁不互斥（大家一起读数据么，压根就没冲突）。 但是有一点要注意。就是你想获取写锁，是除当前线程外，不能存在其它的读锁的。  好比就是说，我要改里面的数据了，那些获取了读锁的线程，必须通通退出来，否则会出现读到老数据的问题（类似事物里面的脏读） ，获取到写锁之后，其它线程也不能再获取到读锁了。

升级的意思就是，读锁在获取写锁之前，一定要先释放读锁。

#### 虚假唤醒
线程可能在没有嗲用过notify或notifyAll的情况下醒来。
```java
public class MyWaitNotify2{

  MonitorObject myMonitorObject = new MonitorObject();
  boolean wasSignalled = false;

  public void doWait(){
    synchronized(myMonitorObject){
      if(!wasSignalled){//must be while!!!!
        try{
          myMonitorObject.wait();
         } catch(InterruptedException e){...}
      }
      //clear signal and continue running.
      wasSignalled = false;
    }
  }

  public void doNotify(){
    synchronized(myMonitorObject){
      wasSignalled = true;
      myMonitorObject.notify();
    }
  }
}
```
Windows API和posix Thread在signal thread时，可能会一次唤醒多个thread，这种看似bug的实现，因为概率极低不影响效率演进为一种通用并发模式
详见effective java item69
即使从等待线程的角度看似已经发出了条件变量的信号之后，等待的条件仍可能为假。原因之一是虚假的唤醒。也就是说，即使没有线程向条件变量发出信号，线程也可能从等待状态中唤醒。为了正确起见，然后有必要在线程完成等待之后验证条件确实为真。由于虚假唤醒可能会重复发生，因此可以通过在条件为真时终止的循环内部等待来实现。

#### AtomicIntegerFieldUpdater
这个类是一个基于反射的使用的工具类，可以对指定类的指定的被volatile修饰的int型字段进行原子更新。
这个类设计用于同一节点的多个字段独立进行的原子更新的原子数据结构
类似于我不要求你这整个类操作具有原子性，我只要求你里面一个字段操作具有原子性。

注意：这个类中的CAS操作弱于其他的原子类，因为没法确保这个字段的所有访问和操作都是基于原子操作的，只能提供对同一个Updater的compareAndSet和set方法的保证

有些规则：字段必须是volatile类型的，在线程之间共享变量时保证立即可见等等。

## 站在巨人的肩膀上
J.U.C中包含了一些「通用高效bug少」的并发数据结构和工具。我们应该更多的使用他们。

### 线程池
如果为每个连接创建一个线程，当请求连接的速度高于处理连接的速度时，系统的线程数也会随之快速增长，服务器将停止服务甚至崩溃。这就给了拒绝服务攻击可乘之机。为每个连接都创建线程的代价也无法忽视。
我们可以使用线程池避免这些问题
```java
//线程池的大小设置为可用处理器数的2倍
int threadPoolSize = Runtime.getRuntime().availableProcessors() * 2;
ExecutorService executor = Executors.newFixedThreadPool(threadPoolSize);
while(true) {
  Socket socket = server.accept();
  executor.execute(new ConnectionHandler(socket));
}
```

### 写入时复制
记得我们放过一个保护性复制吗？外星那里。java标准库提供了优雅的现成方案：CopyOnWriteArrayList
```java
//---皆是方法
 private CopyOnWriteArrayList<ProgressListener> listeners;         //使用一个写入时拷贝对象。当原对象要发生写入的时候，对其做一份克隆，然后对克隆对象操作。

  public Downloader(URL url, String outputFilename) throws IOException {
    in = url.openConnection().getInputStream();
    out = new FileOutputStream(outputFilename);
    listeners = new CopyOnWriteArrayList<ProgressListener>();
  }
  public void addListener(ProgressListener listener) {
    listeners.add(listener);
  }
  public void removeListener(ProgressListener listener) {
    listeners.remove(listener);
  }
  private void updateProgress(int n) {
    for (ProgressListener listener: listeners)
      listener.onProgress(n);
  }
//---
```

### 一个绝好的例子
解决一个世纪的小问题：Wikipedia上出现频率最高的词是什么？
看上去似乎并不难。我们先从基本的开始：
一个简单的串行程序统计前100000页的词要花多久？
```java
public static void main(String[] args) throws Exception {
    Iterable<Page> pages = new Pages(100000, "enwiki.xml");
    for(Page page: pages) {
        Iterable<String> words = new Words(page.getText());
        for(String word:words)
            countWord(word);
    }
}
private static void countWord(String word){
    Integer currentCount = counts.get(word);
    if(currentCount == null)
        counts.put(word,1);
    else
        counts.put(word,currentCount+1);
}
```
首先解析并构造一个page，然后「消费」这个page，对page中的内容统计词频
——于是我们归结出生产者消费者模式，我们可以创建一个生产者，一个消费者。
```java
//----生产者
class Parser implements Runnable {
  private BlockingQueue<Page> queue;

  public Parser(BlockingQueue<Page> queue) {
    this.queue = queue;
  }
  
  public void run() {
    try {
      Iterable<Page> pages = new Pages(100000, "enwiki.xml");
      for (Page page: pages)
        queue.put(page);
    } catch (Exception e) { e.printStackTrace(); }
  }
}
//-----消费者
class Counter implements Runnable {
  private BlockingQueue<Page> queue;
  private Map<String, Integer> counts;
  
  public Counter(BlockingQueue<Page> queue,
                 Map<String, Integer> counts) {
    this.queue = queue;
    this.counts = counts;
  }

  public void run() {
    try {
      while(true) {
        Page page = queue.take();
        if (page.isPoisonPill())
          break;

        Iterable<String> words = new Words(page.getText());
        for (String word: words)
          countWord(word);
      }
    } catch (Exception e) { e.printStackTrace(); }
  }

  private void countWord(String word) {
    Integer currentCount = counts.get(word);
    if (currentCount == null)
      counts.put(word, 1);
    else
      counts.put(word, currentCount + 1);
  }
}
//创建线程
ArrayBlockingQueue<Page> queue = new ArrayBlockingQueue<Page>(100);
HashMap<String, Integer> counts = new HashMap<String, Integer>();

Thread counter = new Thread(new Counter(queue, counts));
Thread parser = new Thread(new Parser(queue));
long start = System.currentTimeMillis();

counter.start();
parser.start();
parser.join();
queue.put(new PoisonPill());
counter.join();
```
存放网页的队列可以采用ArrayBlockingQueue。它提供了高效的并发put()和take()，这些方法会在必要时阻塞：当对一个空队列take程序会阻塞直到队列非空，put()同理。之所以采用阻塞队列，是因为如果生产者的速度比消费者快很多，很容易就占用大量内存空间(指非阻塞的ConcurrentLinkedQueue)
毒丸对象(PoisonPill)：　“毒丸”是指一个放在队列上的对象，其含义是：“当得到这个对象时，立即停止"。自己可以定义一个毒丸对象，用于告诉消费者可以停止了。
运行一下，发现变快了。生产消费者模型优势显现出来：可以并行生产消费、并可以有多个生产消费者。显然整体运行时间会降到生产和消费两者中较长的时间，统计的部分。要进一步优化，就要对统计过程进行并行化，建立多个消费者。

首先我们想到由Collection包的synchronizedMap提供的*同步*的map，遗憾的是这类同步的集合并不提供原子的读-改-写的方法，所以不能使用它们，如果使用HashMap，就必须自己实现对访问的同步。
```java
  private void countWord(String word) {
    lock.lock();
    try {
      Integer currentCount = counts.get(word);
      if (currentCount == null)
        counts.put(word, 1);
      else
        counts.put(word, currentCount + 1);
    } finally { lock.unlock(); }
  }
//---------启动多个消费者

    ArrayBlockingQueue<Page> queue = new ArrayBlockingQueue<Page>(100);
    HashMap<String, Integer> counts = new HashMap<String, Integer>();
    ExecutorService executor = Executors.newCachedThreadPool();
    for (int i = 0; i < NUM_COUNTERS; ++i)
      executor.execute(new Counter(queue, counts));
    Thread parser = new Thread(new Parser(queue));
    long start = System.currentTimeMillis();
    parser.start();
    parser.join();
    for (int i = 0; i < NUM_COUNTERS; ++i)
      queue.put(new PoisonPill());
    executor.shutdown();
    executor.awaitTermination(10L, TimeUnit.MINUTES);

```
使用了线程池，方便管理多个线程。必须使用适当数量的毒丸，保证消费者的线程都可以退出。
结果不如人所愿，变慢了！慢了一倍之多。
这是因为**过度竞争**————过多地线程尝试同时使用一个共享资源。在我们的程序中，消费者花费大量时间等待被其他消费者锁住的counts，等待的时间比实际运算的时间还要唱，最终导致惨烈的性能下降。
好在无敌的J.U.C还提供了支持原子读-改-写，使用高级并发访问（锁分段，lock striping）的`ConcurrentHashMap`
```java
private void countWord(String word) {
  while (true) {
    Integer currentCount = counts.get(word);
    if (currentCount == null) {
      if (counts.putIfAbsent(word, 1) == null)
        break;
    } else if (counts.replace(word, currentCount, currentCount + 1)) {
      break;
    }
  }
}
//------------
ArrayBlockingQueue<Page> queue = new ArrayBlockingQueue<Page>(100);
ConcurrentHashMap<String, Integer> counts = new ConcurrentHashMap<String, Integer>();
ExecutorService executor = Executors.newCachedThreadPool();

for (int i = 0; i < NUM_COUNTERS; ++i)
  executor.execute(new Counter(queue, counts));
Thread parser = new Thread(new Parser(queue));
```
使用了putIfAbsent()和replace()来取代原来的put()方法，可以查阅相关APIs的文档
再次进行消费者数量提升时的时间统计，发现没什么太大问题了——但是在4个以上的消费者时，提速开始下降了。
我们注意到消费者对counts有一些不必要的竞争。与其所有消费者都共享一个counts，还不如每个消费者各自维护一个计数map，再对计数map进行合并

如果看的细致一点，就是1点1点的多线程计数还是count+count的多线程计数。还是共享一个counts的。
```java
public void run() {
  try {
    while(true) {
      Page page = queue.take();
      if (page.isPoisonPill())
        break;
      Iterable<String> words = new Words(page.getText());
      for (String word: words)
        countWord(word);
    }
    mergeCounts();
  } catch (Exception e) { e.printStackTrace(); }
}

private void countWord(String word) {
  Integer currentCount = localCounts.get(word);
  if (currentCount == null)
    localCounts.put(word, 1);
  else
    localCounts.put(word, currentCount + 1);
}

private void mergeCounts() {
  for (Map.Entry<String, Integer> e: localCounts.entrySet()) {
    String word = e.getKey();
    Integer count = e.getValue();
    while (true) {
      Integer currentCount = counts.get(word);
      if (currentCount == null) {
        if (counts.putIfAbsent(word, count) == null)
          break;
      } else if (counts.replace(word, currentCount, currentCount + count)) {
        break;
      }
    }
  }
}
```
成了

### 自习
+ 阅读ForkJoinPool的文档，fork/join框架与线程池有什么区别？
+ 什么是work-stealing？适用于什么场景？J.U.C提供了什么工具实现它？
+ CountDownLatch和CyclicBarrier有什么区别？分别适用什么？
+ 什么是阿姆达尔定律？如何计算出词频统计程序的最大理论加速比？
+ 为什么毒丸方法会被广泛采用？

#### forkjoinpool
Fork/Join并行方式是获取良好的并行计算性能的一种最简单同时也是最有效的设计技术。Fork/Join并行算法是我们所熟悉的分治算法的并行版本。fork操作将会启动一个新的并行Fork/Join子任务。join操作会一直等待直到所有的子任务都结束。Fork/Join算法，如同其他分治算法一样，总是会递归的、反复的划分子任务，直到这些子任务可以用足够简单的、短小的顺序方法来执行。

ForkJoinPool 的另一个特性是它使用了work-stealing（工作窃取）算法：线程池内的所有工作线程都尝试找到并执行已经提交的任务，或者是被其他活动任务创建的子任务（如果不存在就阻塞等待）。这种特性使得 ForkJoinPool 在运行多个可以产生子任务的任务，或者是提交的许多小任务时效率更高。尤其是构建异步模型的 ForkJoinPool 时，对不需要合并（join）的事件类型任务也非常适用。
线程池中每个工作线程（ForkJoinWorkerThread）都对应一个任务队列（WorkQueue），工作线程优先处理来自自身队列的任务（LIFO或FIFO顺序，参数 mode 决定），然后以FIFO的顺序随机窃取其他队列中的任务。在一个线程正在偷取任务时，另外一个线程是无法完成偷取操作的。大体上讲，我们起码有一定概率保证了阻塞性。如果一个偷取操作失败，偷取线程会选择另外一个随机目标继续尝试。。

fork:当前线程不是个ForkJoinWorkerThread的时候，则加入到ForkJoinPool线程池(基于ExecutorService实现);
如果当前线程已经是个ForkJoinWorkerThread了，则把这个任务加入到当前线程的workQueue;
这是和普通线程池不同的地方，task并不是交给线程池中的queue，而是放到线程本地的workQueue

大致上可以认为是ForkJoinPool每个线程都有自己的队列,ThreadPoolExecutor共用一个队列。

ForkJoinPool最适合计算密集型任务，而且最好是非阻塞任务。
偷的话很简单，双向队列。cas解决竞争(最后一个或争抢)。

#### work-stealing
上面讲了，还是写下吧
1. 每个线程都有自己的双端队列
2. 当调用fork方法时，将任务放进队列头部，线程以LIFO顺序，使用push/pop方式处理队列中的任务
3. 如果自己队列里的任务处理完后，会从其他线程维护的队列尾部使用poll的方式窃取任务，以达到充分利用CPU资源的目的
4. 从尾部窃取可以减少同原线程的竞争
5. 当队列中剩最后一个任务时，通过cas解决原线程和窃取线程的竞争


#### CountDownLatch与CyclicBarrier
https://www.jianshu.com/p/bce9f156080f
CountDownLatch是一个同步的辅助类，允许一个或多个线程，等待其他一组线程完成操作，再继续执行。
CyclicBarrier是一个同步的辅助类，允许一组线程相互之间等待，达到一个共同点，再继续执行。
他们都是:Synchronization aid，我把它翻译成同步辅助器，既然是辅助工具，怎么使用啊？哪些场景使用啊？

+ CountDownLatch是不可重置的，所以无法重用；而CyclicBarrier则没有这种限制，可以重用。
+ CountDownLatch的基本操作组合是countDown/await。调用await的线程阻塞等待countDown足够的次数，不管你是在一个线程还是多个线程里countDown，只要次数足够即可。所以说CountDownLatch操作的是事件。
+ CyclicBarrier的基本操作组合，则就是await。当所有的伙伴（parties）都调用了await，才会继续进行任务，并自动进行重置。注意，正常情况下，CyclicBarrier的重置都是自动发生的，如果我们调用reset方法，但还有线程在等待，就会导致等待线程被打扰，抛出BrokenBarrierException异常。CyclicBarrier侧重点是线程，而不是调用事件，它的典型应用场景是用来等待并发线程结束。

对于CountDownLatch来说，重点是“一个线程（多个线程）等待”，而其他的N个线程在完成“某件事情”之后，可以终止，也可以等待。而对于CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。

CountDownLatch是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而CyclicBarrier更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。


#### 阿姆达尔定律
在启动一个并行化项目前，开发人员会希望预估他们能够实现的性能提升量（加速比）。 如果知道（或预估出)能够以并行方式执行的串行代码的百分数，那么开发人员可使用阿姆达尔定律计算应用的加速比上限，无需实际编写任何并发代码。
pctpar：并行执行时间
p：内核数
$$
speedup <= \frac{1} {(1-pctpar)+\frac{pctpar}{p}}
$$
这里忽略了实际开销，例如通信、同步和其它线程管理，以及无限内核处理器的假设，阿姆达尔定律一直饱受批评。 除了没有考虑并发算法固有的开销，对阿姆达尔定律最强烈的批评之一是，随着内核数量的增加，处理的数据量也可能会增加。 阿姆达尔定律假设不论内核数量如何，数据集大小均为固定，并且整体串行执行时间保持不变。

#### 古斯塔夫森定律
如果使用 8 核的并行应用能够计算的数据集是原始大小的 8 倍，串行部分的执行时间会增加吗？ 即使有增加，它也并非与数据集的增加同比例增长。 实际数据显示串行执行时间几乎保持不变。斯塔夫森定律又被称为扩展的加速比(scaled speedup)，它考虑了数据大小与内核数量成比例的增加并计算应用的加速比（上限），假设大数据集能够以并行方式执行。 扩展的加速比公式如下：
p代表内核数量。 为简化表述，对于指定的数据集大小， s 代表并行应用中的串行执行时间的百分数。
$$
speedup <= p + (1-p)s
$$

#### 毒丸
对不起，毒丸基本上找不到资料。找到的是另一个资料...emmm我觉得并发队列里常用的手法吧，很合理，可能也不需要这名字


